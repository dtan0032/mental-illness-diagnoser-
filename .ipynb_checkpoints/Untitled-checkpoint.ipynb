{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4414d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import subprocess\n",
    "\n",
    "# implement pip as a subprocess:\n",
    "# subprocess.check_call([sys.executable, '-m', 'pip', 'install',\n",
    "# 'speech_recognition'])\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "# packages for audio recog\n",
    "import speech_recognition as sr\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "from termcolor import colored\n",
    "import spacy\n",
    "import re\n",
    "from afinn import Afinn\n",
    "import pandas as pd\n",
    "import moviepy.editor as mp\n",
    "import os\n",
    "from pathlib import Path\n",
    "import en_core_web_sm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#                                                                                                       #\n",
    "#                                           AUDIO RECOG                                                 #\n",
    "#                                                                                                       #\n",
    "#########################################################################################################\n",
    "\n",
    "def transcribe(audio_file):\n",
    "    # transcribe audio file\n",
    "    AUDIO_FILE = audio_file\n",
    "\n",
    "    # use the audio file as the audio source\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(AUDIO_FILE) as source:\n",
    "            audio = r.record(source)  # read the entire audio file\n",
    "\n",
    "            text = r.recognize_google(audio)\n",
    "            l1 = ['kill', 'die', 'regret', 'buried', 'dead', 'suicide', 'annoying', 'annoy', 'cold-hearted',\n",
    "                  'ignore', 'loser', 'stress', 'stressed']\n",
    "            l2 = [\"awesome\", \"happy\", \"good\", 'yay', 'beautiful', 'pretty', 'handsome', 'fabulous', 'great', 'best']\n",
    "\n",
    "            formattedText = []\n",
    "            for t in text.lower().split():\n",
    "                if t in l1:\n",
    "                    formattedText.append(colored(t, 'white', 'on_red'))\n",
    "                elif t in l2:\n",
    "                    formattedText.append(colored(t, 'white', 'on_green'))\n",
    "                else:\n",
    "                    formattedText.append(t)\n",
    "\n",
    "            print (\"text: \" + \" \".join(formattedText))\n",
    "            return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def text_sentence_audioF(audio_file):\n",
    "\n",
    "    # nlp = spacy.load(\"en_core_web_sm\")\n",
    "    nlp = en_core_web_sm.load()\n",
    "\n",
    "    text  = transcribe(audio_file)\n",
    "    token = nlp(text)\n",
    "\n",
    "    PRP_lst = []\n",
    "    for i in range (len(token)):\n",
    "        if token[i].tag_ == 'PRP':\n",
    "            PRP_lst.append(str(token[i]))\n",
    "\n",
    "\n",
    "    # \\b means word boundaries.\n",
    "    regex = r\"\\b(?:{})\\b\".format(\"|\".join(PRP_lst))\n",
    "\n",
    "\n",
    "    res = re.split(regex, text)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sentiment_analyzer_audioF(audio_file):\n",
    "    text  = text_sentence_audioF(audio_file)\n",
    "\n",
    "    af = Afinn()\n",
    "\n",
    "    # compute sentiment scores (polarity) and labels\n",
    "    sentiment_scores = [af.score(element) for element in text]\n",
    "    sentiment = ['positive' if score > 0\n",
    "                              else 'negative' if score < 0\n",
    "                                  else 'neutral'\n",
    "                                      for score in sentiment_scores]\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['text'] =  text\n",
    "    df['sentiments'] = sentiment\n",
    "    df['scores'] = sentiment_scores\n",
    "    df = pd.DataFrame(df.groupby('sentiments')['scores'].sum()).reset_index()\n",
    "\n",
    "\n",
    "    output = df.values.tolist()\n",
    "    emotion = []\n",
    "    sentim = [\"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "    for i in range (len(output)):\n",
    "        emotion.append(output[i][0])\n",
    "\n",
    "    for sm in sentim:\n",
    "        if sm not in emotion:\n",
    "            output.append([sm, 0.0])\n",
    "\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def video2audio(video_clip):\n",
    "    my_clip = mp.VideoFileClip(video_clip)\n",
    "    my_clip.audio.write_audiofile(video_clip[:-4] + \"_result.wav\")\n",
    "\n",
    "    # return the name of the audio clip\n",
    "    return video_clip[:-4] + \"_result.wav\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def audio_main(video_clip):\n",
    "    path = os.getcwd() + \"/\" + video_clip\n",
    "    audio_file = video2audio(video_clip)\n",
    "\n",
    "\n",
    "    res =  sentiment_analyzer_audioF(audio_file)\n",
    "    return json.dumps(res)\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#                                                                                                       #\n",
    "#                                           FACIAL RECOG                                                #\n",
    "#                                                                                                       #\n",
    "#########################################################################################################\n",
    "# Video snippet\n",
    "from cv2 import cv2\n",
    "import os\n",
    "\n",
    "def snippet(video_clip):\n",
    "    if not os.path.exists(\"Out\"):\n",
    "        os.mkdir(\"Out\")\n",
    "    pathOut = os.getcwd() + \"\"\"\\Out\\\\\"\"\"\n",
    "\n",
    "    vid = video_clip\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    count = 0\n",
    "    # counter += 1\n",
    "    success = True\n",
    "    while success:\n",
    "        success, image = cap.read()\n",
    "        # print('read a new frame:',success)\n",
    "        if count % 15 == 0:\n",
    "            cv2.imwrite(pathOut + 'frame%d.jpg'%count, image)\n",
    "        count += 1\n",
    "\n",
    "# predicting using model\n",
    "import numpy as np # linear algebra\n",
    "import json\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def my_model():\n",
    "    model = Sequential()\n",
    "    input_shape = (48,48,1)\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=input_shape, activation='relu', padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (5, 5), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def getData(filename):\n",
    "    Y = []\n",
    "    X = []\n",
    "    first = True\n",
    "    for line in open(filename):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            row = line.split(',')\n",
    "            Y.append(int(row[0]))\n",
    "            X.append([int(p) for p in row[1].split()])\n",
    "\n",
    "    X, Y = np.array(X) / 255.0, np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "def facial_main(video_clip):\n",
    "    snippet(video_clip)\n",
    "    model=my_model()\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    model = keras.models.load_model('model_1.h5')\n",
    "\n",
    "    results = []\n",
    "    directory = os.getcwd() + \"\\Out\"\n",
    "\n",
    "    snips = os.listdir(directory)\n",
    "    for pic in snips:\n",
    "        img = image.load_img(directory + \"\\\\\" + pic, grayscale=True, target_size=(48, 48))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis = 0)\n",
    "        x /= 255\n",
    "\n",
    "        custom = model.predict(x)\n",
    "        results.append(custom[0])\n",
    "\n",
    "    res = [0,0,0,0,0,0,0]\n",
    "    for i in range(len(results)):\n",
    "        for j in range(len(results[i])):\n",
    "            res[j] += results[i][j]\n",
    "\n",
    "    out = []\n",
    "    for i in range(len(objects)):\n",
    "        out.append([objects[i],res[i]])\n",
    "    return json.dumps(out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "#                                                                                                       #\n",
    "#                                       MAIN (lambda_handler)                                           #\n",
    "#                                                                                                       #\n",
    "#########################################################################################################\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    video_clip = os.getcwd() + \"\\happy.mp4\"\n",
    "    audio_output = audio_main(video_clip)\n",
    "    facial_output = facial_main(video_clip)\n",
    "\n",
    "    # TODO implement\n",
    "    return audio_output, facial_output\n",
    "\n",
    "print(lambda_handler(0, 0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
